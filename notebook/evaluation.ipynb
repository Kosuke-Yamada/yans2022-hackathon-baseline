{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input_file\", type=str, required=True)\n",
    "parser.add_argument(\"--output_dir\", type=str, required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME=\"predict_helpful_votes\"\n",
    "RUN_NAME=\"cl-tohoku_bert-base-japanese_lr1e-5\"\n",
    "\n",
    "args_list = [\"--input_file\", \"../data/predict/\"+EXPERIMENT_NAME+\"/\"+RUN_NAME+\"/training-val.jsonl\", \\\n",
    "            \"--output_dir\", \"../data/evaluation/\"+EXPERIMENT_NAME+\"/\"+RUN_NAME+\"/\"]\n",
    "# args_list = [\"--input_file\", \"../data/predict/\"+EXPERIMENT_NAME+\"/\"+RUN_NAME+\"/leader_board.jsonl\", \\\n",
    "#             \"--output_dir\", \"../data/evaluation/\"+EXPERIMENT_NAME+\"/\"+RUN_NAME+\"/\"]\n",
    "# args_list = [\"--input_file\", \"../data/predict/\"+EXPERIMENT_NAME+\"/\"+RUN_NAME+\"/final_result.jsonl\", \\\n",
    "#             \"--output_dir\", \"../data/evaluation/\"+EXPERIMENT_NAME+\"/\"+RUN_NAME+\"/\"]\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(args.output_dir):\n",
    "    os.makedirs(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(args.input_file, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_submit_format(df, score_column, mode=\"pred\"):\n",
    "    output_list = []\n",
    "    for product_idx in sorted(set(df[\"product_idx\"])):\n",
    "        df_product = df[df[\"product_idx\"] == product_idx]\n",
    "        scores = [\n",
    "            {\"review_idx\": i, mode + \"_score\": s}\n",
    "            for i, s in zip(df_product[\"review_idx\"], df_product[score_column])\n",
    "        ]\n",
    "        output_list.append({\"product_idx\": product_idx, mode + \"_list\": scores})\n",
    "    return pd.DataFrame(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = convert_to_submit_format(df, \"pred_helpful_votes\", \"pred\")\n",
    "output_pred_file = args.output_dir + \"submit_\" + args.input_file.split(\"/\")[-1]\n",
    "df_pred.to_json(output_pred_file, orient=\"records\", force_ascii=False, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"helpful_votes\" in df.columns:\n",
    "    df_true = convert_to_submit_format(df, \"helpful_votes\", \"true\")\n",
    "    df_merge = pd.merge(df_pred, df_true, on=\"product_idx\")\n",
    "\n",
    "    sum_ndcg = 0\n",
    "    for df_dict in df_merge.to_dict(\"records\"):\n",
    "        df_eval = pd.merge(\n",
    "            pd.DataFrame(df_dict[\"pred_list\"]),\n",
    "            pd.DataFrame(df_dict[\"true_list\"]),\n",
    "            on=\"review_idx\",\n",
    "        )\n",
    "        ndcg = ndcg_score([df_eval[\"true_score\"]], [df_eval[\"pred_score\"]], k=5)\n",
    "        sum_ndcg += ndcg\n",
    "\n",
    "    output_eval_file = (\n",
    "        args.output_dir\n",
    "        + \"eval_\"\n",
    "        + args.input_file.split(\"/\")[-1].replace(\".jsonl\", \".json\")\n",
    "    )\n",
    "    with open(output_eval_file, \"w\") as f:\n",
    "        json.dump(\n",
    "            {\"ndcg@5\": sum_ndcg / len(df_merge)}, f, indent=4, ensure_ascii=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('yans2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60bc8e6a080301f68f145aa2d4ce6eacb9f122f704035ed4e5e80f593963d0f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
